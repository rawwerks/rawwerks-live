+++
date = "2018-08-08"
draft = false
title = "Money Can't Buy Knives"
slug = "money-cant-buy-knives"
tags = ["science","PhD","out-teach","deep tech","PhD to CEO"]
image = ""
comments = true	# set false to hide Disqus
share = true	# set false to hide share buttons
menu= ""		# set "main" to add this content to the main menu
author = "Raymond A Weitekamp"
+++

Most technology startups involve some amount of engineering risk. Can we build it at scale? Can we build it for $X by our launch date? Can we refine the product to be attractive before we run out of money? There is a ton of material from the lean/agile world on how to approach these challenges. I've read it all. Frankly, while much of this advice has been useful to me in my transition from [PhD to CEO](http://phdtoceo.com/) - the existing literature just wasn't very applicable to the very early stages of [polySpectra](http://polyspectra.com). 

The problem was that polySpectra was facing significant *scientific risk* - which I want to distinguish from other types of engineering or technical risk. A key differentiating feature of scientific risk is that the probability of solving the problem does not necessarily increase with more money and time. (In other words, the outcome is a highly non-linear function of effort.) Most scientific questions lead to more questions, rather than answers. If you are writing a software product, you can pretty much guarantee from the beginning (if you are competent) that it *can* be done, with enough time and money. If you are building hardware which utilizes components already on the market, same thing. It might not come together exactly as imagined, but you can be sure that the product is possible within the known laws of the universe. If, on the other hand, you are trying to figure out if newly discovered molecule behaves the way you want it to - forget about it.

Enter [Surf Ninjas](https://www.amazon.com/Surf-Ninjas-Dan-Gordon/dp/B0000696HW/ref=as_li_ss_tl?ie=UTF8&qid=1533746106&sr=8-1&keywords=surf+ninjas+dvd&linkCode=ll1&tag=rawwerks09-20&linkId=eb2947bd29f1fc919591db383744f874&language=en_US) (indisputably the greatest film of all time). For the context of this article, you really only need to remember one line from the movie, young Rob Schneider's sage advice that "money can't buy knives". I've embedded the clip below, but I'm sure this link will break eventually. The metaphor: true scientific breakthroughs are the Knives of Kwantsu - you can't simply buy them. It has to be your destiny to find them.
{{< youtube KbLyWfwczbQ >}}

***

The point that I am trying to make here is that most of the agile methodologies (and classic Silicon Valley playbooks) out there will not help you address true scientific risk. It is very hard to "[scrum](https://www.amazon.com/Essential-Scrum-Practical-Addison-Wesley-Signature/dp/0137043295/ref=as_li_ss_tl?ie=UTF8&qid=1533748991&sr=8-1-spons&keywords=scrum&psc=1&linkCode=ll1&tag=rawwerks09-20&linkId=5294c77f75e83fea8db37ef0d23de671&language=en_US)" when you cannot predict the outcome of any of your experiments. (Believe me, we've tried.) Having more money might help you prove (or disprove) your hypothesis faster, but it might not. "Move fast and break things" assumes that there is a working product to break in the first place. What you need isn't money, it is a place to do science, a team, and (ideally) a community of scientists to inspire you to develop new ideas. For us, that was [Berkeley Lab](http://lbl.gov) and the [Molecular Foundry](http://foundry.lbl.gov), via [Cyclotron Road](http://cyclotronroad.org). 

Here is my advice for deep tech companies that still have significant scientific risk: 

 * *Find your foundry.* Keep it in the lab for as long as possible. Don't raise a bunch of money just to run your first experiment. Find a home that already has the basic research infrastructure you need to attack the most fundamental risks. These types of deep tech incubators are popping up all over the place, as universities and labs realize that they can build mutually beneficial partnerships with startups.
 * *A publication is not a product.* You probably have way more scientific risk left than you think, because you are a biased expert. If you can't transfer your process to a new lab, with a new person running everything - you still have scientific risk. If you can't teach a contract manufacturer how to make a railroad car full of your new material - you likely still have scientific risk (although your scale-up might be considered engineering risk if the process is well-precedented).
 * *Who has done this before?* There is nothing new under the sun. Someone has gone through a similar challenge in the past. They can't tell you the answers, but they can give you frameworks, benchmarks, protocols and processes to accelerate your scientific derisking. Find them.

Deep tech needs a different playbook. If it offends you that Silicon Valley refers to programmers as 'engineers', you'll likely agree. There is a small community starting to put that playbook together the hard way. If you want to help, learn, or just peek at a work in progress, please consider signing up for my newsletter PhD to CEO.

<script async data-uid="02921326b7" src="https://f.convertkit.com/02921326b7/fc4d50c02c.js"></script>

***

*RAWWERKS is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.com*